{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbee4e9d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pnd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6efdaf",
   "metadata": {},
   "source": [
    "# <h1 style=\"color: red;\">Section 1: Data</h1>\n",
    "\n",
    "# <h2>1) Préparation de données</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf1d843",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(44) #à chaque exécution,générer le même dataset de manière aléatoire\n",
    "# Coefficients\n",
    "a1, a2, b = 2, 3, 5  # y = 2*X1 + 3*X2 + 5 + bruit\n",
    "nombre_points = 100 # Nombre de points\n",
    "# Génération des deux features (X1 et X2)\n",
    "X1 = np.random.rand(nombre_points) * 10\n",
    "X2 = np.random.rand(nombre_points) * 10\n",
    "# Empilement des features dans une seule matrice (shape: (100, 2))\n",
    "X = np.column_stack((X1, X2))\n",
    "# Génération du bruit\n",
    "bruit = np.random.randn(nombre_points) * 2  # Bruit\n",
    "# Calcul de la target\n",
    "y = a1 * X1 + a2 * X2 + b + bruit\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baeb093",
   "metadata": {},
   "source": [
    "# <h1 style=\"color: red;\">Section 2: Neural network avec tensorflow</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259f0e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc78ff9",
   "metadata": {},
   "source": [
    "# <h2>2) Modèle de réseau de neurones</h2>\n",
    "\n",
    "# <h3>2-a) Architecture de réseau de neurones</h3>\n",
    "\n",
    "# <h4>2-a-1) Proposition d'une architecture</h4>\n",
    "# Un réseau de neurones composé de :\n",
    "# - 2 inputs (X1,x2). Chaque input est accompagné par un weight.\n",
    "# - Un bias\n",
    "# - Unité de calcul 1 : Une sommation pondérée, z=w1.X1+w2.X2+bias\n",
    "# - Unité de calcul 2 : Une activation, f(z). f peut être linear, sigmoid, relu,...\n",
    "\n",
    "# <h4>2-a-2) À partir de la nature du dataset, établir les inputs du réseau de neurones</h4>\n",
    "# Les inputs de notre réseau de neurones sont X1 et X2, soit 2 inputs.\n",
    "# En termes de dimensions, notre input_shape est (2,) car il y a 2 features.\n",
    "\n",
    "# <h4>2-a-3) À partir de la nature du dataset, établir le nombre de neurones à mettre dans outputlayer du réseau de neurones</h4>\n",
    "# Comme nous réalisons une régression pour prédire une seule valeur y, \n",
    "# nous avons besoin d'un seul neurone dans la couche de sortie.\n",
    "\n",
    "# <h4>2-a-4) À partir de la nature de target, établir la fonction d'activation de la couche d'output</h4>\n",
    "# Comme nous faisons une régression linéaire, la fonction d'activation appropriée \n",
    "# pour la couche de sortie est 'linear' (ou pas d'activation).\n",
    "\n",
    "# <h3>2-b) Sans aucune couche cachée, créer un modèle basé sur un réseau de neurones « model_nn » qui correspond à ce problème</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10446288",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_nn = Sequential([\n",
    "    # Un seul neurone en sortie avec activation linéaire, sans couche cachée\n",
    "    Dense(units=1, activation='linear', input_shape=(2,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edc9434",
   "metadata": {},
   "source": [
    "# <h3>2-c) Compiler le modèle</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6415c0df",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_nn.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce58021f",
   "metadata": {},
   "source": [
    "# <h3>2-d) Entraîner le modèle</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8890e9d3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "history = model_nn.fit(X_train, y_train, epochs=100, batch_size=8, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e5276",
   "metadata": {},
   "source": [
    "# <h3>2-e) Préciser ce que fait la fonction fit</h3>\n",
    "# La fonction fit:\n",
    "# 1. Prend les données d'entrée (X_train) et les cibles (y_train)\n",
    "# 2. Divise les données en batchs de taille spécifiée (batch_size=8)\n",
    "# 3. Propage les données à travers le réseau pour chaque batch\n",
    "# 4. Calcule l'erreur entre les prédictions et les vraies valeurs\n",
    "# 5. Rétropropage l'erreur pour ajuster les poids à l'aide de l'optimiseur (adam)\n",
    "# 6. Répète ce processus pour le nombre d'époques spécifié (epochs=100)\n",
    "# 7. Retourne un historique contenant les métriques d'entraînement\n",
    "\n",
    "# <h3>2-f) Quel est le nombre de paramètres du réseau</h3>\n",
    "# Calcul à la main:\n",
    "# - 2 poids (w1, w2) pour les 2 entrées\n",
    "# - 1 biais\n",
    "# Total: 3 paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33421329",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Affichage du détail du réseau\n",
    "model_nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8116ccf",
   "metadata": {},
   "source": [
    "# <h3>2-g) Afficher les paramètres du réseau de neurones</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f713f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "weights, bias = model_nn.layers[0].get_weights()\n",
    "print(\"Poids du réseau de neurones:\")\n",
    "print(f\"w1: {weights[0][0]}\")\n",
    "print(f\"w2: {weights[1][0]}\")\n",
    "print(f\"bias: {bias[0]}\")\n",
    "print(f\"Vrais coefficients: a1={a1}, a2={a2}, b={b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c16b0c",
   "metadata": {},
   "source": [
    "# <h3>2-h) Dessiner le réseau de neurones en utilisant les paramètres trouvés</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf16a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([0, 1], [0, 0], 'k-', linewidth=2)  # Ligne horizontale\n",
    "plt.plot([1, 2], [0, 0], 'k-', linewidth=2)  # Ligne horizontale\n",
    "\n",
    "# Inputs\n",
    "plt.scatter([0, 0], [-0.5, 0.5], s=100, c='blue', label='Inputs')\n",
    "plt.annotate('X1', (0, 0.5), fontsize=12)\n",
    "plt.annotate('X2', (0, -0.5), fontsize=12)\n",
    "\n",
    "# Poids\n",
    "plt.annotate(f'w1={weights[0][0]:.3f}', (0.5, 0.25), fontsize=10)\n",
    "plt.annotate(f'w2={weights[1][0]:.3f}', (0.5, -0.25), fontsize=10)\n",
    "\n",
    "# Neurone de sortie\n",
    "plt.scatter([1], [0], s=200, c='red', label='Sommation')\n",
    "plt.annotate('Σ', (1, 0), fontsize=15, ha='center', va='center')\n",
    "plt.annotate(f'bias={bias[0]:.3f}', (1, -0.2), fontsize=10)\n",
    "\n",
    "# Output\n",
    "plt.scatter([2], [0], s=150, c='green', label='Output (Linear)')\n",
    "plt.annotate('ŷ', (2, 0), fontsize=15, ha='center', va='center')\n",
    "\n",
    "plt.title('Architecture du réseau de neurones linéaire')\n",
    "plt.grid(False)\n",
    "plt.axis('off')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c07f65",
   "metadata": {},
   "source": [
    "# <h3>2-i) Dans quels cas il est important de faire des régulations (tuning)</h3>\n",
    "# Les régulations (tuning) sont importantes dans les cas suivants:\n",
    "# 1. Surapprentissage (overfitting): Quand le modèle performe bien sur les données d'entraînement mais mal sur les données de test\n",
    "# 2. Sous-apprentissage (underfitting): Quand le modèle ne capture pas bien la structure des données\n",
    "# 3. Données complexes: Quand les relations entre variables sont non-linéaires ou complexes\n",
    "# 4. Grands réseaux: Plus un réseau est grand, plus il risque de surapprendre\n",
    "# 5. Données limitées: Quand on dispose de peu d'exemples d'entraînement\n",
    "#\n",
    "# Les techniques de régulation incluent:\n",
    "# - La régularisation L1/L2 pour pénaliser les grands poids\n",
    "# - Le dropout pour réduire la co-adaptation des neurones\n",
    "# - La normalisation par lots (batch normalization)\n",
    "# - L'arrêt précoce (early stopping) basé sur la performance de validation\n",
    "\n",
    "# <h2>3) Prédiction en utilisant le modèle</h2>\n",
    "\n",
    "# <h3>3-a) En utilisant le modèle, faire les prédictions en utilisant X_test</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b975ff5d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "yhat_nn = model_nn.predict(X_test)\n",
    "yhat_nn = yhat_nn.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c157619d",
   "metadata": {},
   "source": [
    "# <h3>3-b) En utilisant les paramètres du modèle, faire une prédiction sans utiliser predict</h3>\n",
    "# Calcul manuel des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38d1cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "yhat_manual = np.dot(X_test, weights) + bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1798ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Évaluer le modèle en utilisant MSE, R²\n",
    "mse_train = mean_squared_error(y_train, yhat_train)\n",
    "r2_train = r2_score(y_train, yhat_train)\n",
    "\n",
    "print(f\"Performance sur l'ensemble d'entraînement:\")\n",
    "print(f\"MSE: {mse_train:.4f}\")\n",
    "print(f\"R²: {r2_train:.4f}\")\n",
    "\n",
    "# Calculer les résidus\n",
    "residus_train = y_train - yhat_train\n",
    "\n",
    "# Tracer le graphique des résidus\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(yhat_train, residus_train)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.title('Graphique des résidus (ensemble d\\'entraînement)')\n",
    "plt.xlabel('Valeurs prédites')\n",
    "plt.ylabel('Résidus')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Interprétation des résultats\n",
    "# La répartition des résidus autour de zéro nous indique si notre modèle est biaisé.\n",
    "# Des résidus uniformément répartis autour de zéro indiquent un bon modèle.\n",
    "# Des tendances dans les résidus indiquent que le modèle ne capture pas certaines relations.\n",
    "\n",
    "# <h3>4-b) Performance du modèle sur test set</h3>\n",
    "# Évaluer le modèle sur l'ensemble de test\n",
    "mse_test = mean_squared_error(y_test, yhat_nn)\n",
    "r2_test = r2_score(y_test, yhat_nn)\n",
    "\n",
    "print(f\"Performance sur l'ensemble de test:\")\n",
    "print(f\"MSE: {mse_test:.4f}\")\n",
    "print(f\"R²: {r2_test:.4f}\")\n",
    "\n",
    "# Calculer les résidus\n",
    "residus_test = y_test - yhat_nn\n",
    "\n",
    "# Tracer le graphique des résidus\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(yhat_nn, residus_test)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.title('Graphique des résidus (ensemble de test)')\n",
    "plt.xlabel('Valeurs prédites')\n",
    "plt.ylabel('Résidus')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1c5693",
   "metadata": {},
   "source": [
    "# <h3>4-c) À quoi peut servir d'évaluer le modèle en utilisant training set et test set en même temps</h3>\n",
    "# Évaluer le modèle sur les ensembles d'entraînement et de test en même temps permet de:\n",
    "#\n",
    "# 1. Détecter le surapprentissage (overfitting):\n",
    "#    - Si les performances sont bonnes sur l'ensemble d'entraînement mais mauvaises sur l'ensemble de test,\n",
    "#      cela indique un surapprentissage.\n",
    "#\n",
    "# 2. Évaluer la capacité de généralisation:\n",
    "#    - Une faible différence entre les performances sur les deux ensembles indique une bonne généralisation.\n",
    "#\n",
    "# 3. Guider le réglage des hyperparamètres:\n",
    "#    - Permet d'ajuster les hyperparamètres pour optimiser la généralisation plutôt que juste la performance\n",
    "#      sur les données d'entraînement.\n",
    "#\n",
    "# 4. Valider la stabilité du modèle:\n",
    "#    - Un modèle stable devrait avoir des performances similaires sur les deux ensembles.\n",
    "#\n",
    "# 5. Détecter les problèmes de distribution:\n",
    "#    - Des différences importantes peuvent révéler que les distributions des ensembles d'entraînement\n",
    "#      et de test sont différentes.\n",
    "\n",
    "# <h1>From scratch</h1>\n",
    "\n",
    "# <h1 style=\"color: red;\"> Section 3: Régression linéaire from scratch </h1>\n",
    "\n",
    "# <h2>Modèle (version1) de régression linéaire from scratch avec utilisation des matrices</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf61e23",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegressionScratch:\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X, y, learning_rate=0.01, epochs=1000):\n",
    "        # Initialisation des paramètres\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Historique des pertes pour visualisation\n",
    "        losses = []\n",
    "        \n",
    "        # Algorithme de descente de gradient\n",
    "        for i in range(epochs):\n",
    "            # Prédictions avec les paramètres actuels\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "            \n",
    "            # Calcul des gradients\n",
    "            dw = (1/n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1/n_samples) * np.sum(y_pred - y)\n",
    "            \n",
    "            # Mise à jour des paramètres\n",
    "            self.weights -= learning_rate * dw\n",
    "            self.bias -= learning_rate * db\n",
    "            \n",
    "            # Calcul de la perte (MSE)\n",
    "            loss = (1/n_samples) * np.sum((y_pred - y)**2)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            # Affichage de la progression tous les 100 epochs\n",
    "            if i % 100 == 0:\n",
    "                print(f'Epoch {i}, Loss: {loss:.4f}')\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "# Création et entraînement du modèle from scratch\n",
    "linear_reg_scratch = LinearRegressionScratch()\n",
    "losses = linear_reg_scratch.fit(X_train, y_train, learning_rate=0.01, epochs=1000)\n",
    "\n",
    "# Visualisation de l'évolution de la perte\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(losses)\n",
    "plt.title('Évolution de la perte (MSE) pendant l\\'entraînement')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "yhat_scratch = linear_reg_scratch.predict(X_test)\n",
    "\n",
    "# Évaluation du modèle from scratch\n",
    "mse_scratch = mean_squared_error(y_test, yhat_scratch)\n",
    "r2_scratch = r2_score(y_test, yhat_scratch)\n",
    "\n",
    "print(f\"MSE (modèle from scratch): {mse_scratch:.4f}\")\n",
    "print(f\"R² (modèle from scratch): {r2_scratch:.4f}\")\n",
    "\n",
    "# Comparaison des poids appris avec les vrais coefficients\n",
    "print(\"Poids appris (from scratch):\", linear_reg_scratch.weights)\n",
    "print(\"Biais appris (from scratch):\", linear_reg_scratch.bias)\n",
    "print(\"Vrais coefficients: a1 =\", a1, \", a2 =\", a2, \", b =\", b)\n",
    "\n",
    "# Comparaison des deux modèles\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, yhat_nn)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')\n",
    "plt.title('Prédictions (Réseau de neurones)')\n",
    "plt.xlabel('Valeurs réelles')\n",
    "plt.ylabel('Prédictions')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, yhat_scratch)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')\n",
    "plt.title('Prédictions (Régression linéaire from scratch)')\n",
    "plt.xlabel('Valeurs réelles')\n",
    "plt.ylabel('Prédictions')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tableau comparatif des performances\n",
    "comparaison = {\n",
    "    'Modèle': ['Réseau de neurones', 'Régression linéaire from scratch'],\n",
    "    'MSE sur test': [mse_test, mse_scratch],\n",
    "    'R² sur test': [r2_test, r2_scratch]\n",
    "}\n",
    "\n",
    "df_comparaison = pnd.DataFrame(comparaison)\n",
    "print(df_comparaison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe35950",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dataset fourni\n",
    "X = np.array([[1, 2], \n",
    "              [3, 4], \n",
    "              [5, 6], \n",
    "              [7, 8]])\n",
    "y = np.array([10, 20, 30, 40])\n",
    "\n",
    "# Paramètres initiaux\n",
    "bias = 0.1\n",
    "weights = np.array([[0.2], [0.3]])\n",
    "\n",
    "# a) Calcul de la prédiction\n",
    "def predict(X, weights, bias):\n",
    "    return np.dot(X, weights) + bias\n",
    "\n",
    "y_pred = predict(X, weights, bias)\n",
    "print(\"a) Prédictions:\")\n",
    "print(y_pred.flatten())  # Aplatir pour un affichage plus propre\n",
    "\n",
    "# b) Calcul des erreurs\n",
    "def calculate_errors(y_true, y_pred):\n",
    "    return y_pred - y_true\n",
    "\n",
    "errors = calculate_errors(y, y_pred)\n",
    "print(\"\\nb) Erreurs:\")\n",
    "print(errors.flatten())\n",
    "\n",
    "# c) Calcul des gradients\n",
    "def calculate_gradients(X, errors):\n",
    "    n_samples = X.shape[0]\n",
    "    # Gradient pour les poids\n",
    "    dw = (1/n_samples) * np.dot(X.T, errors)\n",
    "    # Gradient pour le biais\n",
    "    db = (1/n_samples) * np.sum(errors)\n",
    "    return dw, db\n",
    "\n",
    "dw, db = calculate_gradients(X, errors)\n",
    "print(\"\\nc) Gradients:\")\n",
    "print(\"dw:\", dw.flatten())\n",
    "print(\"db:\", db)\n",
    "\n",
    "# d) Mise à jour du modèle\n",
    "def update_parameters(weights, bias, dw, db, learning_rate=0.01):\n",
    "    weights = weights - learning_rate * dw\n",
    "    bias = bias - learning_rate * db\n",
    "    return weights, bias\n",
    "\n",
    "learning_rate = 0.01\n",
    "new_weights, new_bias = update_parameters(weights, bias, dw, db, learning_rate)\n",
    "print(\"\\nd) Paramètres mis à jour:\")\n",
    "print(\"Nouveaux poids:\", new_weights.flatten())\n",
    "print(\"Nouveau biais:\", new_bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
